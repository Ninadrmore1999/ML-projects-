{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5rLhcRS0YiANzMwarG/nO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ninadrmore1999/ML-projects-/blob/main/Telecom_customer_churn_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYe5Ohwkh_1H"
      },
      "source": [
        "Let's load the data of our business case now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBIjzf6Egl1F"
      },
      "outputs": [],
      "source": [
        "#Churn prediction in telecom.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhfnibcBiE-V"
      },
      "outputs": [],
      "source": [
        "\n",
        "!gdown 1uUt7uL-VuF_5cpodYRiriEwhsldeEp3m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FajIDgjgiGe5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "churn = pd.read_csv(\"churn_logistic.csv\")\n",
        "churn.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHaGUZTMiH_z"
      },
      "outputs": [],
      "source": [
        "cols = ['Day Mins', 'Eve Mins', 'Night Mins', 'CustServ Calls', 'Account Length']\n",
        "y = churn[\"Churn\"]\n",
        "X = churn[cols]\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4pb_4a3HBm5"
      },
      "source": [
        "Let's split the data into training, validation and testing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMMLz85dildW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr_cv, X_test, y_tr_cv, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tr_cv, y_tr_cv, test_size=0.25,random_state=1)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIj0eXhEHEye"
      },
      "source": [
        "We will scale our data before fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5sKDuSqilzL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pwLHoPNinkH"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PPE8YpEipDr"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1ldXZSTiuMG"
      },
      "outputs": [],
      "source": [
        "model.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lUeLcybiv3I"
      },
      "outputs": [],
      "source": [
        "model.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIVezXs1AEBn"
      },
      "outputs": [],
      "source": [
        "model.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfLISD6Ci4kb"
      },
      "source": [
        "## Accuracy Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8bjT-QoQyJ_"
      },
      "source": [
        "Let's implement our accuracy metric now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOMCquoAi2Ja"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  return np.sum(y_true==y_pred)/y_true.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPFCgiJcNDm-"
      },
      "outputs": [],
      "source": [
        "accuracy(y_train, model.predict(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2gxBt_RS3YZ"
      },
      "outputs": [],
      "source": [
        "accuracy(y_val, model.predict(X_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzEGPA29TOw_"
      },
      "source": [
        "So our model has a validation accuracy of 0.71, or 71.49%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagbDTn3N0LG"
      },
      "source": [
        "##**Hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuxZwtpZNz5Y"
      },
      "source": [
        "\n",
        "Hence let's start doing hyper parameter tuning on parameter $C = \\frac{1}{\\lambda}$  to increase the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVBtRLrTbMA2"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "train_scores = []\n",
        "val_scores = []\n",
        "scaler = StandardScaler()\n",
        "for la in np.arange(0.01, 5000.0, 100): # range of values of Lambda\n",
        "  scaled_lr = make_pipeline(scaler, LogisticRegression(C=1/la))\n",
        "  scaled_lr.fit(X_train, y_train)\n",
        "  train_score = accuracy(y_train, scaled_lr.predict(X_train))\n",
        "  val_score = accuracy(y_val, scaled_lr.predict(X_val))\n",
        "  train_scores.append(train_score)\n",
        "  val_scores.append(val_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-4WX0BUcezZ"
      },
      "source": [
        "Now, let's plot the graph and pick the Regularization Parameter $λ$ which gives the best validation score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u1uS8_AcrMp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(list(np.arange(0.01, 5000.0, 100)), train_scores, label=\"train\")\n",
        "plt.plot(list(np.arange(0.01, 5000.0, 100)), val_scores, label=\"val\")\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.xlabel(\"Regularization Parameter(λ)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjgrgrSuKSAq"
      },
      "source": [
        "\n",
        "- We see how Validation increases to a peak and then decreases\n",
        "\n",
        "- Notice as Regularization is increasing, the Accuracy decreasing since model is moving towards Underfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiChnCjdV22_"
      },
      "source": [
        "Let's take lambda value as 1000 for this data and check the\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGY7gojXPCoW"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(C=1/1000)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCkfn5ycPUBM"
      },
      "outputs": [],
      "source": [
        "accuracy(y_train, model.predict(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_txvnm0xPUBN"
      },
      "outputs": [],
      "source": [
        "accuracy(y_val, model.predict(X_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKs4aurQPnO0"
      },
      "source": [
        "We can observe an increase of 0.01, or 1%, in both training and validation data\n",
        "\n",
        "Let's check our model for test data too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j-b26k9PWGd"
      },
      "outputs": [],
      "source": [
        "accuracy(y_test, model.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGI1HEcX3xB"
      },
      "source": [
        "### Sklearn Code implementation for MultiClass Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAAkds7oBik1"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2aAoXVp-1bQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.inspection import DecisionBoundaryDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x8zt9JRB03X"
      },
      "source": [
        "Creating some data with multiple classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQtc5UXb-1Of"
      },
      "outputs": [],
      "source": [
        "# dataset creation with 3 classes\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples= 498,\n",
        "                           n_features= 2,\n",
        "                           n_classes = 3,\n",
        "                           n_redundant=0,\n",
        "                           n_clusters_per_class=1,\n",
        "                           random_state=5)\n",
        "y=y.reshape(len(y), 1)\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSLrSn-ndKho"
      },
      "source": [
        "Plotting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE89OzPzYZa4"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c = y)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7VVJvodMat"
      },
      "source": [
        "Splitting the data into train validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx0egsivY3z5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr_cv, X_test, y_tr_cv, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tr_cv, y_tr_cv, test_size=0.25,random_state=4)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si9tkDF2dRRY"
      },
      "source": [
        "training the OneVsRest Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNmPrfHPY3L0"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(multi_class='ovr')\n",
        "# fit model\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnaFcUL8dXan"
      },
      "source": [
        "Checking the Accuracy of Training, validation and Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JML2FkWgZ7ZH"
      },
      "outputs": [],
      "source": [
        "print(f'Training Accuracy:{model.score(X_train,y_train)}')\n",
        "print(f'Validation Accuracy :{model.score(X_val,y_val)}')\n",
        "print(f'Test Accuracy:{model.score(X_test,y_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH-yHlhMdw3_"
      },
      "source": [
        "Creating Hyperplane of OVR LogisticRegression for the entire data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8lQncaFRX_I"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMzyjx2bb3_L"
      },
      "outputs": [],
      "source": [
        "_, ax = plt.subplots()\n",
        "DecisionBoundaryDisplay.from_estimator(model, X, response_method=\"predict\", cmap=plt.cm.Paired, ax=ax)\n",
        "plt.title(\"Decision surface of LogisticRegression\")\n",
        "plt.axis(\"tight\")\n",
        "\n",
        "# Plot also the training points\n",
        "colors = \"bry\"\n",
        "for i, color in zip(model.classes_, colors):\n",
        "        idx = np.where(y == i)\n",
        "        plt.scatter(\n",
        "            X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired, edgecolor=\"black\", s=20\n",
        "        )\n",
        "\n",
        "\n",
        "# Plot the three one-against-all classifiers\n",
        "xmin, xmax = plt.xlim()\n",
        "ymin, ymax = plt.ylim()\n",
        "coef = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "def plot_hyperplane(c, color):\n",
        "        def line(x0):\n",
        "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
        "\n",
        "        plt.plot([xmin, xmax], [line(xmin), line(xmax)], ls=\"--\", color=color)\n",
        "\n",
        "for i, color in zip(model.classes_, colors):\n",
        "        plot_hyperplane(i, color)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfcbDZYNd9UF"
      },
      "source": [
        "**Observe**\n",
        "\n",
        "We can see how One-vs-Rest Logistic Regression is able to classify Multi-class Classification data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kCNapNpXsSS"
      },
      "source": [
        "Lets Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cGr2k8dWm-P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0mF8_xxKiYQ"
      },
      "outputs": [],
      "source": [
        "!gdown 1CgBW5H54YfdYtJmYE5GWctaHZSpFt71V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86rUr5nWKiPV"
      },
      "outputs": [],
      "source": [
        "demo1 = pd.read_csv('spam_ham_dataset.csv')\n",
        "demo1.drop(['Unnamed: 0','label'],axis=1,inplace=True)\n",
        "demo1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WXefCyWSH1e"
      },
      "outputs": [],
      "source": [
        "!gdown 1dw56R8SzKgTgiKurfBLUTxmiewJacMkt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIJQnbKsWiEf"
      },
      "outputs": [],
      "source": [
        "dt = pd.read_csv('Spam_finalData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNuOobUgKj-j"
      },
      "outputs": [],
      "source": [
        "dt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4PNs7wsTp3o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(dt.drop(['label_num'],axis=1),dt['label_num'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYrGVXWGZ27M"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts().plot(kind='bar')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Test Data Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1uU5VG7Saij"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvcY03zQSagA"
      },
      "outputs": [],
      "source": [
        "print('Model Accuracy:',model.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxX4qf1UWPbf"
      },
      "source": [
        "# **Confusion Matrix Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEhDiX3fNx5H"
      },
      "source": [
        "#### Lets use sklearn `confusion_matrix` function to get the values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYZ5CvwH8LAc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "conf_matrix # 2D np array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1Sl6BJ8B0lA"
      },
      "source": [
        "But the `ConfusionMatrixDisplay` plotting functionality in sklearn makes this easy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkvwc8swgneQ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KBRzYCA8b_O"
      },
      "outputs": [],
      "source": [
        "# ax used here to control the size of confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "ConfusionMatrixDisplay(conf_matrix).plot(ax = ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TwafusFaG7T"
      },
      "source": [
        "Finding Accuracy using Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVZTOzdhXljb"
      },
      "outputs": [],
      "source": [
        "np.diag(conf_matrix).sum() / conf_matrix.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enuyhDKuB2Fn"
      },
      "source": [
        "# **Precision Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qC1sZTBCoac"
      },
      "source": [
        "Scratch Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NLUadMBCoN4"
      },
      "outputs": [],
      "source": [
        "def precision_calc(conf):\n",
        "  tp = conf[1,1]\n",
        "  fp = conf[0,1]\n",
        "\n",
        "  return tp/(tp+fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6MaONS0C9jh"
      },
      "outputs": [],
      "source": [
        "precision_calc(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx_NS_8-CR_i"
      },
      "source": [
        "Using Sklearn's precision Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TNQhWTECDd4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT92qLSfQpui"
      },
      "source": [
        "**observe**\n",
        "\n",
        "Even though the model has a lower precision value than accuracy:\n",
        "- Its still a great model because of its high precision value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8AsnwmIKuu"
      },
      "source": [
        "# **Recall Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95a45z8YIKuv"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "ConfusionMatrixDisplay(conf_matrix).plot(ax = ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xOXbrgLIKuw"
      },
      "source": [
        "Scratch Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7mHkxMxIKuw"
      },
      "outputs": [],
      "source": [
        "def recall_calc(conf):\n",
        "  tp = conf[1,1]\n",
        "  fn = conf[1,0]\n",
        "\n",
        "  return tp/(tp+fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlwdfFOKIKuw"
      },
      "outputs": [],
      "source": [
        "recall_calc(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H-7n1XbIKuw"
      },
      "source": [
        "Using Sklearn's precision Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiiRpR_4IKuw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylcOf4pvQ4aw"
      },
      "source": [
        "**observe**\n",
        "\n",
        "The model's recall value is almost very close to accuracy :\n",
        "- It shows the  model has very low FN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1-Score"
      ],
      "metadata": {
        "id": "RrOFCtseeFyJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqPMkpqvYW5l"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay(conf_matrix).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4CvRvc5YZ-f"
      },
      "source": [
        "scratch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgEAU_REYWwF"
      },
      "outputs": [],
      "source": [
        "pre = precision_calc(conf_matrix)\n",
        "re = precision_calc(conf_matrix)\n",
        "\n",
        "f1 = 2* (pre*re)/(pre+re+1e-6)\n",
        "\n",
        "print(f'f1Score:{f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY-kc-359ry0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgT84tMk9uoY"
      },
      "outputs": [],
      "source": [
        "print(f'f1Score:{f1_score(y_test,y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80boumUDY732"
      },
      "source": [
        "**observe**\n",
        "\n",
        "Clearly our model is a very decent one:\n",
        "- Cause even after imbalance data\n",
        "- the model f1 score is great.\n",
        "\n",
        "The difference in scratch implementation and Sklearn f1score:\n",
        "- Because Sklearn uses a different value to counter zero division"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvR4y3bPXv5k"
      },
      "source": [
        "# Spam vs Non-Spam: Business Case\n",
        "\n",
        "\n",
        "\n",
        "You are working in Google and have a task to create an Email spam detection model\n",
        "\n",
        "Here,\n",
        "- **not spam** → Class 0\n",
        "- **spam** → Class 1\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Note:** For simplicity, lets call:\n",
        "-  Class 0 **Not Spam** as Negative Class\n",
        "- and Class 1 **Spam** as Positive Class\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgywmY7ZXv5k"
      },
      "source": [
        "Lets Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELAteGVHXv5k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "!gdown 1dw56R8SzKgTgiKurfBLUTxmiewJacMkt\n",
        "\n",
        "dt = pd.read_csv('Spam_finalData.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(dt.drop(['label_num'],axis=1),dt['label_num'])\n",
        "\n",
        "y_test.value_counts().plot(kind='bar')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Test Data Distribution')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(f'Training Data:{X_train.shape},{y_train.shape}, Testing Data: {X_test.shape},{y_test.shape}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RYK4cm5-nUV"
      },
      "source": [
        "\n",
        "# **AU-ROC curve Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27x73f5i-qF7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVl-dXq5q8C-"
      },
      "source": [
        "stores model probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9n7A1YTqxyU"
      },
      "outputs": [],
      "source": [
        "probability = model.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OPha7n0rh-e"
      },
      "outputs": [],
      "source": [
        "probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y0deRX5rkSZ"
      },
      "source": [
        "**Observe**\n",
        "\n",
        "```Probability``` variable contains 2 probability $P(Y=1 |X)$ and $P(Y=0 |X )$\n",
        "\n",
        "#### But for thresholding we need only one probability, what can be done ?\n",
        "\n",
        "Ans: lets consider only $ p = P(Y=1 |X) $\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNqpd-8RsF9o"
      },
      "outputs": [],
      "source": [
        "probabilites = probability[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkjN56jH-9SO"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thr = roc_curve(y_test,probabilites)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI-IVTwy_GqL"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr,tpr)\n",
        "\n",
        "#random model\n",
        "plt.plot(fpr,fpr,'--',color='red' )\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQBr2yHj_usm"
      },
      "outputs": [],
      "source": [
        "# AUC\n",
        "roc_auc_score(y_test,probabilites)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46GW1TMyAC3A"
      },
      "source": [
        "# **Precision Recall curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofo_5VgUAFtN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-RJNrvVAJ-g"
      },
      "outputs": [],
      "source": [
        "precision, recall, thr = precision_recall_curve(y_test, probabilites)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ_6Wtc9ARXj"
      },
      "outputs": [],
      "source": [
        "plt.plot(recall, precision)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('PR curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDm2bNPuBMPb"
      },
      "outputs": [],
      "source": [
        "auc(recall, precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OaxNncwyX7F"
      },
      "source": [
        "**observe**\n",
        "\n",
        "Now the **AU-PRC** comes close to F1 score\n",
        "- Showing that **PRC** worked just fine in imbalanced data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbGUNeC2wCng"
      },
      "source": [
        "## **Class weight Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGm8rvk0JeaW"
      },
      "source": [
        "\n",
        "Lets now see how its implemented in Sklearn for Logisitic Regression:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEI5GAg0umMQ"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts().plot(kind='bar')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Train Data Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIBjJv1ou6HZ"
      },
      "source": [
        "**observe**\n",
        "\n",
        "The training data:\n",
        "- Non-spam data = 2727\n",
        "- Spam data = 1151\n",
        "\n",
        "Hence weightage parameter becomes:\n",
        "- $W_i = \\frac{2727}{1151} = 2.37$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7WRZEuav24T"
      },
      "outputs": [],
      "source": [
        "# Model creation, prediction\n",
        "\n",
        "def training(model,X_train,y_train,X_test,y_test):\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  train_y_pred = model.predict(X_train)\n",
        "  test_y_pred = model.predict(X_test)\n",
        "\n",
        "  train_score = f1_score(y_train, train_y_pred)\n",
        "  test_score = f1_score(y_test, test_y_pred)\n",
        "\n",
        "  return train_score,test_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBdRqWzaaJTu"
      },
      "outputs": [],
      "source": [
        "# minority class needs more re-weighting\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model = LogisticRegression(class_weight={0:1,1:2.37})\n",
        "\n",
        "f1_train,f1_test = training(model,X_train,y_train,X_test,y_test)\n",
        "print(f'Training F1 score:{f1_train}, Testing F1 score:{f1_test}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCcL7_7ve8F4"
      },
      "source": [
        "**Observe**\n",
        "\n",
        "how introducing Weighted-loss,\n",
        "- did not do much change in F1-score\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "#### What can be the reason ?\n",
        "Ans: lets check the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua5sz9wsaJTv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "ConfusionMatrixDisplay(conf_matrix).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDFCpzs6Z7e"
      },
      "source": [
        "**Observe**\n",
        "\n",
        "Clearly, by introducing Class weights,\n",
        "- Model has predicted many Non-Spam emails as Spam ($FP ⇑$)\n",
        "- Hence the F1 score is low"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGKV99fi_G3F"
      },
      "source": [
        "#**Oversampling code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pF_qOQy_Gdz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Create an instance of RandomOverSampler\n",
        "oversampler = RandomOverSampler()\n",
        "\n",
        "# Perform oversampling on the training data\n",
        "print('Before Oversampling')\n",
        "print(y_train.value_counts())\n",
        "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "print('After Oversampling')\n",
        "print(y_train_oversampled.value_counts())\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "f1_train,f1_test = training(model,X_train_oversampled, y_train_oversampled,X_test,y_test)\n",
        "\n",
        "print(f'Training F1 score:{f1_train}, Testing F1 score:{f1_test}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUdmF5xMAikj"
      },
      "source": [
        "**Observe**\n",
        "\n",
        "Training F1 Score is much higher than testing F1 Score\n",
        "\n",
        "<br>\n",
        "\n",
        "#### What can be said when training performance > testing performance ?\n",
        "\n",
        "Ans: Model Overfits\n",
        "- This means if we add same repitive samples of minority class, **it can lead to overfitting**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MwkEr_jeTWr"
      },
      "source": [
        "#### Why does model overfits in oversampling technique ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Pu8MIPENr3"
      },
      "source": [
        "\n",
        "\n",
        "Ans: because oversampling just **repeats samples**\n",
        "- This makes the model to over learn patterns\n",
        "\n",
        "<br>\n",
        "\n",
        "#### What can be a smarter approach for oversampling ?\n",
        "Ans: Instead of repeating the samples:\n",
        "- Lets create **synthetically new samples** for our minority class label\n",
        "\n",
        "- This approach will provide new samples to the model so it does not over learns any patterns\n",
        "\n",
        "<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G-xs8Zu64ZC"
      },
      "source": [
        "# **SMOTE (Synthetically Minority Oversampling Technique)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOrndORGhFym"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Create an instance of SMOTE\n",
        "smt = SMOTE()\n",
        "\n",
        "\n",
        "# Perform SMOTE on the training data\n",
        "print('Before SMOTE')\n",
        "print(y_train.value_counts())\n",
        "\n",
        "X_sm, y_sm = smt.fit_resample(X_train, y_train)\n",
        "print('After Oversampling')\n",
        "print(y_train_oversampled.value_counts())\n",
        "\n",
        "model = LogisticRegression(C= 5, penalty= 'l1', solver = 'liblinear')\n",
        "\n",
        "f1_train,f1_test = training(model,X_sm, y_sm,X_test,y_test)\n",
        "\n",
        "print(f'Training F1 score:{f1_train}, Testing F1 score:{f1_test}')\n",
        "\n"
      ]
    }
  ]
}